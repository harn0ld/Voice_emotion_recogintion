# VOICE EMOTION RECOGNITION PROJECT

## Overview
This project focuses on **voice emotion recognition** using **digital signal processing (DSP) and deep learning techniques**. It involves **feature extraction from audio signals** using spectrograms, **MFCCs**, and **Fourier Transform**, followed by classification using **machine learning and neural networks**.

## Key Features
- **Audio Preprocessing**: Noise reduction and feature extraction from voice recordings.
- **Feature Engineering**: Used **FFT, spectrograms, and MFCCs** to analyze speech data.
- **Deep Learning Model**: Implemented a **TensorFlow/Keras-based neural network** for classification.
- **Machine Learning Pipeline**: Trained and evaluated **various classifiers** for emotion recognition.
- **Visualization**: Used **matplotlib and librosa** to display frequency spectrograms and MFCCs.

## Technologies Used
- **Python (NumPy, Pandas, SciPy, Matplotlib, Librosa)**
- **Deep Learning (TensorFlow/Keras)**
- **Machine Learning (scikit-learn, feature scaling, classifiers)**
- **Digital Signal Processing (Fourier Transform, Spectrogram Analysis, MFCCs)**
- **Google Colab for experimentation**

## What I Learned
- **Signal Processing**: Mastered **FFT, spectrograms, and MFCCs** for speech analysis.
- **Deep Learning for Audio**: Implemented **neural networks** to classify emotions from speech.
- **Data Preprocessing**: Enhanced audio data through **noise reduction and standardization**.
- **Model Training & Evaluation**: Trained **ML and deep learning models**, optimizing performance.

## Usage
1. Preprocess raw voice recordings (denoising, feature extraction).
2. Generate spectrograms and MFCCs for feature representation.
3. Train and evaluate models for emotion classification.
4. Analyze and visualize the results.

## Contributors
- **Davide Croatto**
- **Hubert Nowak**
- **Eleonora Zullo**

